{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Machine Learning I, Programming Exercise 0\n",
    "\n",
    "The first notebook is supposed to introduce you to the basic tools you need in order to code machine learning applications in Python. We will go through them each at a time and apply them to a machine learning problem in the last part of this exercise.\n",
    "\n",
    "The idea is that a basic skeleton and some glue code for each exercise is already prepared for you, and you are then supposed to amend the missing parts or just change the code if you feel like it.\n",
    "\n",
    "If you can read this, you have probably managed to set up a Python installation with a working Jupyter server. Good Job so far! In case you have never used a Jupyter Notebook before, you might be wondering what it is all about. The goal of a notebook is to keep documentation, code and output in one place, making it a great tool for explaining all kinds of concepts and scientific discoveries to other people. Each notebook is made of two types of cells:\n",
    "* **Markdown** cells containing formatted text (like this one)\n",
    "* **Code** cells containing Python code that can be run from the browser. To do so press the run button at the toolbar above the notebook or press `Ctrl`+`Enter` to run the highlighted code cell.\n",
    "\n",
    "Note that global variables and imports from one cell are preserved and available to subsequently executed cells. It is possible to execute the code cells in any arbitrary order, however this notebook is designed to run from top to bottom, since later cells depend on imports and variables from earlier cells. Besides, it is also a good idea to execute the cells one by one instead of just running the whole notebook at once. That gives you the opportunity to read the code beforehand and perform any modifications that might be needed on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Numpy\n",
    "First, we will install the Numpy package designed for general-purpose numerical computations. Since Python comes with a built-in package manager on most systems this is surprisingly easy: Just change the command in the following cell depending on whether you use `conda` or `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you have installed your Python environment using conda (which I'd recommend),\n",
    "# the following line should do the job:\n",
    "!conda install --yes --prefix {sys.prefix} numpy\n",
    "# Or in case you don't use conda comment the previous line and try using pip instead:\n",
    "# !{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After importing the library, we can now start working with the provided routines and data types.\n",
    "\n",
    "### 1.1 Array Creation & Shape\n",
    "The fundamental data structure in Numpy is the multi-dimensional `ndarray`. It behaves much like a high-level version of an array in lower-level languages like C and can hold a variety of data types. Once created, neither size nor datatype can be changed and unlike with a python list each element needs to be of the same data type.\n",
    "\n",
    "It is easy to create arrays from lists and other iterable objects in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5,6,7,8])\n",
    "print(f'x shape: {x.shape}, dtype {x.dtype}.')\n",
    "y = np.array([[1,2,3,4], [5.0,6,7,8]])\n",
    "print(f'y shape: {y.shape}, dtype {y.dtype}.')\n",
    "z = np.array(list('Hello World!'))\n",
    "print(f'z shape: {z.shape}, dtype {z.dtype}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Apart from that, there are also factory methods available to create special arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "a = np.zeros((2, 4))  # Arry filled with zeros\n",
    "print(f'a shape: {a.shape}, dtype {a.dtype}.')\n",
    "b = np.random.rand(8)  # Each element is independently drawn from a uniform distribution on the interval [0, 1)\n",
    "print(f'b shape: {b.shape}, dtype {b.dtype}.')\n",
    "c = np.arange(start=1, stop=9)  # Returns an array with elements [start, start+1, ..., stop-1]\n",
    "print(np.all(x == c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is not possible to change the *size* of an array once it is created, changing the *shape* is quite easy, as long as the new shape fits the size of the array. Note that such a `reshape` operation does not return a copy of the original array, instead it is just a *view* to the same memory location that can be indexed in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.reshape(2, 4))\n",
    "print(x.reshape(4, -1))  # -1 means that the number in this dimension should be computed automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple arrays of matching shape can also be 'stacked' together in a single array. However, this operation creates the resulting array in a new memory location, i.e, a copy needs to be performed. The position of the newly created axis can be controlled by the `axis` keyword. It is also possible to concatenate two arrays along an existing axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.stack([x.reshape(2, 4), y], axis=0).shape)  # Create new axis as the first axis\n",
    "print(np.stack([x.reshape(2, 4), y], axis=2).shape)  # Create new axis as the last axis\n",
    "print(np.concatenate([x.reshape(2, 4), y], axis=0).shape)  # Concatenate along the existing first axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 Basic Arithmetic Operations\n",
    "Arithmetic operations are usually computed on a per-element basis, meaning that they are separately applied to each element in the array. Since Numpy overloads most python operators for the `ndarray` class, it is easy to write code that works with scalars as well as arrays:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    return np.sqrt(a**2 + b**2)\n",
    "\n",
    "print(f(3, 4))\n",
    "print(f(np.arange(5), np.ones((5,))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from arithmetic operations, comparisons are also supported on a per-element basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([5, 3, 7, 4, 8, 1])\n",
    "b = np.array([4, 6, 3, 4, 7, 9])\n",
    "print(a >= b)\n",
    "print((a<3) | (a>6))  # Note that the bitwise or operator is used instead of logical or.\n",
    "                      # For Numpy arrays this corresponds to an element-wise or."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An important concept when it comes to element-wise operations is called *broadcasting*. It allows us to apply a binary, elementwise operation on two arrays of different shapes in a meaningful way. One special case of that is the use of a scalar and an `ndarray` in the same operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here the value `2` is 'broadcast' two every element of `x`, making this equivalent to the follwing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x + np.array([2, 2, 2, 2, 2, 2, 2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The only difference is that no memory is wasted for a second array of the same size as `x`. This concept also carries over to multi-dimensional arrays, as long as they have the same number of elements in all but one axis and one array has only one element in that axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(y + np.array([[4, 3, 2, 1]]))\n",
    "a = np.random.rand(12, 13, 6, 4, 5)\n",
    "b = np.random.rand(12, 1, 6, 4, 5)\n",
    "print((a - b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Apart from the element-wise operations Numpy also provides reduction functions that aggregate over one or several axes of an array. Most common operations are supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sum(y))\n",
    "print(np.max(x))\n",
    "print(np.mean(y, axis=1))\n",
    "print(np.prod(y, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3 Array Indexing\n",
    "Elements within an array can be accessed by using square brackets, just like in normal python lists. In multi-dimensional arrays, one index for each dimension can be specified. Contrary to, for example, MATLAB, indices start from zero and negative indices are counted backwards from the last element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x[3])\n",
    "print(y[-1])\n",
    "print(y[-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is also possible to access *slices* of an array by specifying `start:stop:step` instead of an integer as an index for the dimension that should be sliced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x[1:6])\n",
    "print(x[:5])  # Select first 5 elements\n",
    "print(x[-5:])  # Select last 5 elements\n",
    "print(x[::-1])  # Reverse x\n",
    "print(y[:, 1])  # select 2nd column of y, a single colon means that the whole axis should be selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Furthermore, you can index a Numpy array with another Numpy array. This is called *advanced indexing* and the way it works depends on the type of the index array:\n",
    "* `bool`: Indexing with a boolean array works like a mask: Only those elements where the index is `True` are selected in the new array. The boolean array must be of the same shape as the array we wish to select from\n",
    "* `int`: The indices are used to select specific elements from the array. One index array per axis of the original array is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx1 = np.array([True, True, True, False, False, True, True, False])\n",
    "print(x[idx1])\n",
    "idx2 = np.array([0, 1, 2, 5, 6])\n",
    "print(x[idx2])\n",
    "idx3 = np.array([0, 2, 3])\n",
    "print(y[0, idx3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Linear Algebra Operations\n",
    "Numpy also supports all basic linear algebra operations such as matrix-matrix multiplication and matrix-vector multiplication. No special dataypes are needed for that, instead Numpy treats 2D arrays as matrices and 1D arrays as vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "B = np.eye(3)  # Identity matrix\n",
    "b = np.array([0, 1, 0])\n",
    "print(np.matmul(A, B))\n",
    "print(np.matmul(A, b))  # np.matmul supports matrix-matrix and matrix-vector products\n",
    "print(np.dot(b, b))  # inner (scalar) product of two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ex. 1.5 One-Liners (optional)\n",
    "The following exercises can all be solved by writing just one line of code for each, possibly combining several of the concepts mentioned above. It is also possible to solve them with only the functions that have been introduced or used up until this point! And that is exactly what you should do: **Write one line of code using only the given functions!**\n",
    "\n",
    "1. Given a matrix $A = (\\begin{matrix}\\mathbf{a}_1 & \\mathbf{a}_2 & \\ldots & \\mathbf{a}_{20} \\end{matrix}) \\in \\mathbb{R}^{20 \\times 20}$, compute the matrix \n",
    "\\begin{equation*}\n",
    "    A' = \\left(\\begin{matrix}\\frac{\\mathbf{a}_1}{\\lVert \\mathbf{a}_1 \\rVert_2} & \\frac{\\mathbf{a}_2}{\\lVert \\mathbf{a}_2 \\rVert_2} & \\ldots & \\frac{\\mathbf{a}_{20}}{\\lVert \\mathbf{a}_{20} \\rVert_2} \\end{matrix}\\right),\n",
    "\\end{equation*}\n",
    "i.e., divide each column vector by its Euclidean norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(20, 20)\n",
    "# here goes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Print the indices of all elements in `arr` that are larger or equal to 32 and smaller than 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 100, size=10)\n",
    "print(arr)\n",
    "# here goes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Given array `arr`, compute a new array of the same length as follows: `arr2[i] = sqrt(arr[i-1]) + arr[i])`, where out of bounds indices should be mapped to the other end of the array, like in a ring buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 100, size=10)\n",
    "print(arr)\n",
    "# here goes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Given array `arr` compute the 1D max pooling operation with a window size of 3. In other words, partition the array into blocks of 3 elements and only return the maximum element from each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 100, size=30)\n",
    "print(arr)\n",
    "# here goes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Assume you are given two sets of vectors: $\\mathcal{S} = \\{\\mathbf{s}_1, \\mathbf{s}_2, \\ldots, \\mathbf{s}_{20}\\}$ and $\\mathcal{T} = \\{\\mathbf{t}_1, \\mathbf{t}_2, \\ldots, \\mathbf{t}_{15}\\}$, where $\\mathbf{s}_i, \\mathbf{t}_j \\in \\mathbb{R}^{10}$ for all $i, j$. Compute a matrix $M \\in \\mathbb{R}^{20 \\times 15}$ that contains the dot product for every possible combination of vectors from $\\mathcal{S}$ and $\\mathcal{T}$, i.e.,\n",
    "\\begin{equation*}\n",
    "    M_{i,j} = \\langle \\mathbf{s}_i, \\mathbf{t}_j \\rangle \\quad \\text{for all } i \\in \\{1, \\ldots, 20\\}, j \\in \\{1, \\ldots, 15\\}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "S = [np.random.rand(10) for _ in range(20)]\n",
    "T = [np.random.rand(10) for _ in range(15)]\n",
    "print(np.dot(S[2], T[3]))\n",
    "# here goes your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ex. 1.6 The Jacobi Method (optional)\n",
    "The Jacobi method is an iterative algorithm to solve a system of linear equations $Ax = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is a diagonally dominant matrix, meaning that\n",
    "\\begin{equation*}\n",
    "    \\lvert A_{ii} \\rvert > \\sum_{j\\neq i} \\lvert A_{ij} \\rvert\n",
    "\\end{equation*}\n",
    "or in words that the absolute value of each diagonal element is larger than the sum of absolute values of the rest of the corresponding row.\n",
    "\n",
    "The algorithm produces a sequence of iterates $x^{(1)}, x^{(2)}, \\ldots$, where the starting point $x^{(0)}$ can be freely chosen. In each iteration, the following update is performed:\n",
    "\\begin{equation*}\n",
    "    x^{(t+1)}_{i} = \\frac{1}{A_{ii}} \\left(b_i - \\sum_{j \\neq i} A_{ij} x^{(t)}_{j} \\right).\n",
    "\\end{equation*}\n",
    "\n",
    "Termination can be ensured by checking whether two subsequent iterates are sufficietly close, i.e., whether $\\lVert x^{(t+1)} - x^{(t)} \\rVert \\leq \\varepsilon$ for some small $\\varepsilon > 0$ or by enforcing a maximum number of iterations.\n",
    "\n",
    "Your tasks are as follows:\n",
    "1. Generate a random but diagonally dominant matrix $A$ and a random vector $b$. Choose $n=20$.\n",
    "2. Implement the Jacobi method. This consists of two parts:\n",
    "   * Check if the given matrix is actually square and diagonally dominant.\n",
    "   * Implement the update step given above. Terminate after 1000 iterations or when the Euclidean distance between two subsequent iterates becomes less than $\\varepsilon = 10^{-8}$. Don't use any additional loops for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def jacobi(A, b, x_0=None, max_iter=1000, eps=1e-8):\n",
    "    # TODO: Check if A is diagonally dominant and square\n",
    "        \n",
    "    x = np.zeros(n) if x_0 is None else x_0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        # TODO: Perform Jacobi iteration\n",
    "        \n",
    "        # TODO: Test convergence\n",
    "        break\n",
    "    \n",
    "    if i == max_iter-1:\n",
    "        print('Max. iterations reached!')\n",
    "    else:\n",
    "        print(f'Solution found after {i:d} iterations.')\n",
    "      \n",
    "    return x\n",
    "\n",
    "# TODO: Generate random, diagonally dominant matrix\n",
    "n = 20\n",
    "A = np.eye(n)\n",
    "b = np.random.rand(n)\n",
    "\n",
    "# Run Jacobi method\n",
    "x = jacobi(A, b)\n",
    "\n",
    "# Check if solution is correct\n",
    "Ax = np.matmul(A, x)\n",
    "print(f'Ax is {Ax}')\n",
    "print(f'b is {b}')\n",
    "assert(np.allclose(Ax, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Matplotlib\n",
    "[Matplotlib](https://matplotlib.org/) is a (data) visualization library for Python. While it is perhaps not the easiest to learn and the API can be quite obscure in some places, it is widely used in academia and therefore worth having a look at. The amount of things that you can realise with the library is almost limitless, so we can only treat the very basics in this exercise. MATLAB users will find that Matplotlib supports almost all of MATLABS's native plotting commands, which is also one of the library's explicit goals.\n",
    "\n",
    "Installing the library is easy with the package manager of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!conda install --yes --prefix {sys.prefix} matplotlib\n",
    "# !{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are multiple APIs that we can use to access the functions of Matplotlib. The easiest to get started with is probably the MATLAB-like API contained in the `matplotlib.pyplot` module. Luckily, Jupyter Notebook and Matplotlib work nicely together, so that you can make your plots show up directly in the notebook instead of a separate window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# magic command that enables plots to be shown directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Figures and Plots\n",
    "*Figures* in Matplotlib are similar to a canvas in that they can hold multiple *plots*. Those plots could be visualizations of any kind of data in a multitude of ways (see part 2.2 for a non-exhaustive list). Therefore, the starting point of working with Matplotlib is to create a figure that is now considered \"active\" and all subsequent plotting commands will be applied to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, num=100)  # Create an array with 100 points evenly spaced in the interval (-5, 5)\n",
    "y = 0.75*x**2\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4.5))  # (width, height), given in inches\n",
    "plt.title('A test plot')\n",
    "plt.xlabel(r'$\\mathbf{x}$: Some ind. variable')  # Note that LaTeX-Code is supported\n",
    "plt.ylabel('$y$')\n",
    "plt.plot(x, y, label=r'$0.75 x^2$')\n",
    "plt.plot(x, 0.3*x**3, label=r'$0.3 x^3$')\n",
    "plt.grid(linestyle='dashed')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As mentioned earlier, it is also possible to have multiple plots in one figure. This is accomplished by calling the `subplots` function and using the returned `Axes` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=False, sharey='row', figsize=(8, 6))\n",
    "fig.suptitle('A second test plot')\n",
    "\n",
    "axes[0, 0].set_title('Top Left')\n",
    "axes[0, 0].plot(x, 5*x-3)\n",
    "\n",
    "axes[0, 1].set_title('Top Right')\n",
    "axes[0, 1].plot(x, 2*x + 1)\n",
    "\n",
    "axes[1, 0].set_title('Bottom Left')\n",
    "axes[1, 0].plot(x, 2**x)\n",
    "axes[1, 0].set_yscale('log')  # Use log scaling for the y axis. Note that this is also applied to the\n",
    "                              # \"Bottom Right\" plot, since the y axis is shared in every row\n",
    "\n",
    "axes[1, 1].set_title('Bottom Right')\n",
    "axes[1, 1].plot(x+1, (x+1)**2)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.grid(linestyle='dashed')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Plot Types\n",
    "The library offers many types of visualization routines for a variety of data, too many to cover them all in this notebook. The following cell will contain a few select examples examples of what can be done with Matplotlib. If you want to know more, it is always a good idea to have a look at the [documentation](https://matplotlib.org/contents.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data1 = np.random.normal(loc=np.array([1, 2]), size=(20, 2))\n",
    "data2 = np.random.normal(loc=np.array([-2, -1]), size=(20, 2))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False, figsize=(12, 9))\n",
    "\n",
    "axes[0, 0].set_title('Scatter Plot')\n",
    "axes[0, 0].scatter(data1[:, 0], data1[:, 1], label=r'$\\mathcal{N}((1, 2)^T, I)$')\n",
    "axes[0, 0].scatter(data2[:, 0], data2[:, 1], label=r'$\\mathcal{N}((-2, -1)^T, I)$', marker='x')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].set_title('Line Plot')\n",
    "axes[0, 1].plot(x, 2*x + 1, linestyle='dotted')\n",
    "\n",
    "axes[1, 0].set_title('Histogram')\n",
    "_, bins, _ = axes[1, 0].hist([data1[:, 0], data2[:, 0]], bins=10, edgecolor='k', zorder=3, stacked=True)\n",
    "axes[1, 0].set_xticks(bins)\n",
    "axes[1, 0].legend([r'$\\mathcal{N}(1, 1)$', r'$\\mathcal{N}(-2, 1)$'])\n",
    "\n",
    "axes[1, 1].set_title('Boxplot')\n",
    "axes[1, 1].boxplot([data1[:, 0], data2[:, 0]], zorder=3)\n",
    "axes[1, 1].legend([r'$\\mathcal{N}(1, 1)$', r'$\\mathcal{N}(-2, 1)$'])\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.grid(linestyle='dashed')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ex. 2.3 SARS-CoV-2 (optional)\n",
    "The Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) and the disease caused by it, COVID-19, have had a major impact on the lives of people here in Germany and most countries throughout the world during the last year. If you are not too tired of hearing and reading about it in the news day in and day out, you'll have the opportuity to play around with some data concerning the global pandemic in this exercise.\n",
    "\n",
    "For that, we will take data from the [ECDC Website](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) and process it locally. The .csv file you can find under \"Download the data in more formats\" contains one row per country and per day, organized in the following fields:\n",
    "* `dateRep`: The date in `DD/MM/YYYY` format (e.g. `12.04.2020`).\n",
    "* `day`, `month` and `year`: The same date again, but in separate fields.\n",
    "* `countriesAndTerritories`: English name of the country. Spaces are replaced by an underscore (e.g. `United_States_of_America`).\n",
    "* `geoId`, `countryterritoryCode`: Two-digit and three-digit country code (e.g. `US` and `USA`)\n",
    "* `cases`: Number of people that were positively tested for the SARS-CoV-2 on that specific day in that specific country (e.g. `28391`).\n",
    "* `deaths`: Number of people that died of COVID-19 (or perhaps other illnesses facilitated by the virus) on that specific day in that specific country (e.g. `\n",
    "1831`).\n",
    "* `popData2018`: The country's number of inhabitants as of 2018 (e.g. `327167434`)\n",
    "\n",
    "The goal of this exercise is to compare the development of total SARS-CoV-2 cases in different countries. Specifically, we would like to plot the total cases at each day, starting from the day where the total cases first reached 100 in the respective country. Hence, your tasks are as follows:\n",
    "1. Download the dataset and extract relevant parts in a format convenient for further processing. Think about which fields you need for the plot and which countries you want to compare. The code skeleton already contains a few lines that download the data in `.csv` format. If you prefer to use another data format offered by the ECDC Website, feel free to do so.\n",
    "2. Compute the total (or cumulative) number for each day in the data that you extracted in the first step.\n",
    "3. Filter out all days were the number of total cases was less than 100.\n",
    "4. Create a plot with \"Number of days since total cases first reached 100\" as the x-axis and \"Total SARS-CoV-2 cases\" as the y-axis. Use a logarithmic scale for the y-axis and plot one curve for each country that you chose. Also include, as a reference, a hypothetical curve, where the number of cases starts with 100 and doubles every 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from datetime import date\n",
    "import csv\n",
    "\n",
    "def extract_data(reader, countries):\n",
    "    # TODO: extract relevant data\n",
    "    for row in reader:\n",
    "        country = row['countriesAndTerritories']\n",
    "\n",
    "    return []\n",
    "\n",
    "# Load Covid-19 data\n",
    "countries = ['Germany', 'United_States_of_America', 'China']\n",
    "with urlopen('http://opendata.ecdc.europa.eu/covid19/casedistribution/csv') as f:\n",
    "    lines = [line.decode('utf-8') for line in f.readlines()]\n",
    "reader = csv.DictReader(lines)\n",
    "data = extract_data(reader, countries)\n",
    "\n",
    "# TODO: Compute total cases for each day\n",
    "\n",
    "# TODO: Create Data, starting from the day where 100 people have been infected\n",
    "\n",
    "# TODO: hypothetical curve where total cases double every five days\n",
    "\n",
    "# TODO: Plot everything in a log-plot with legend\n",
    "def display_name(country):\n",
    "    return country.replace('_', ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Scikit-Learn\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html) is a popular and widely used library, which contains numerous algorithms for machine learning and data analysis. Furthermore, it also contains tools for pre-processing data, evaluating models and many other utilities.\n",
    "\n",
    "Installing the library is again as easy as issuing one command to the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Datasets\n",
    "Any machine learning algorithm needs some form of input data for training, from which it can recognize patterns and extract knowledge. Usually, several *data points* are collected in experimental or real-world scenarios and merged into a so-called *dataset*. While Scikit-Learn has several utilities for downloading, cleaning and preprocessing such datasets, we are not going use a real-world dataset for the purpose of this exercise. Instead, we will use the function `make_moons` to generate an artifical, two-dimensional dataset in the following code segment. Play around with the `noise` value to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Generate toy data (two moons dataset)\n",
    "n = 200\n",
    "X, Y = datasets.make_moons(n, noise=0.2)\n",
    "\n",
    "# Plot the dataset\n",
    "fig = plt.figure()\n",
    "cmap = ListedColormap([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=cmap, edgecolor='k')\n",
    "plt.grid(linestyle='dashed')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Classification Fundamentals\n",
    "The goal of the classification task is to find a function $f$ that assigns a class label $y$, which is chosen from $K$ different possibilities, to a data point $x$. Training data for such a task is usually given as several input-output pairs, i.e., $D = \\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}$. For the two moons dataset, we would have $x \\in \\mathbb{R}^2$ and $K=2$ and we chose $n=200$.\n",
    "\n",
    "One cool feature of Scikit-Learn is the unified API that makes it easy to switch between different classification algorithms on the fly. This is possible, since the algorithms are implemented as subclasses of `BaseEstimator` which, among others, offers the following fundamental methods:\n",
    "* `fit(X, Y)`: This method trains a classifier, where `X` is a Numpy array of shape `(n, d)` containing `n` training examples and `Y` is another Numpy array containg the class labels for all `n` samples. The actual implementation differs significantly from algorithm to algorithm.\n",
    "* `predict(X)`: Once the classifier has been trained with a call to `fit`, this method can be used to predict a class label for previously unseen datapoints `X` (which is again a Numpy array of shape `(n*, d)`)\n",
    "\n",
    "The following code snippet uses the *Support-Vector-Machine* algorithm to find a classifier that can distinguish the two classes from the two moons dataset. We use both a linear SVM as well as a RBF-kernel SVM. Don't worry if you have never heard of those terms before, since they will be explained in great detail during the lecture! One great thing about libraries like Scikit-Learn is that you don't need to know how a Support Vector Machine works before you can use it, since the implementation is already available and the library is easily accessible, making it easier for people to get started with machine learning. However, if you want to achieve consistently good results, knowledge about the algorithms you are using and a certain amount of experience are needed in order to know which knobs to tweak. So, it still makes sense to attend to lecture (at least digitally) :)\n",
    "\n",
    "For the two-dimensional toy dataset used in this exercise it is also easy to draw the decision surface of the classifier. This means that a point within the blue surface would be classfied as blue by the classifier and a point in the red surface as belonging to the red class. As you can see by playing around, the boundary between the classes is always a line for the linear SVM, whereas it can have any shape for the RBF SVM.\n",
    "\n",
    "There are several ways to evaluate and compare the performance of classifiers, but one easy and often used way is to separate a certain number of randomly chosen points from the given dataset (the *test set*) and use the rest to train the classifier (the *training set*). The percentage of correctly classified points in the test set, called *accuracy*, can then be seen as a measure of the *generalization* performance, i.e., the classifier's ability to transfer learned patterns to a set of similar data that it has never seen before. Scikit-Learn's `train_test_split` function implements exactly this split of data in training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train Classifier on the dataset\n",
    "linear_clf = SVC(kernel='linear', C=0.1)\n",
    "kernel_clf = SVC(kernel='rbf', C=1, gamma=1)\n",
    "\n",
    "classifiers = [(linear_clf, 'linear'),\n",
    "               (kernel_clf, 'RBF')]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# Plot decision surface\n",
    "# First generate grid\n",
    "res = 200  # Resolution of the grid in cells\n",
    "x_max, y_max = np.max(X, axis=0) + 0.25\n",
    "x_min, y_min = np.min(X, axis=0) - 0.25\n",
    "grid_x, grid_y = np.meshgrid(np.linspace(x_min, x_max, res),\n",
    "                             np.linspace(y_min, y_max, res))\n",
    "# Get test array from grid\n",
    "grid_input = np.c_[grid_x.reshape(-1), grid_y.reshape(-1)]\n",
    "\n",
    "rows = (len(classifiers) + 1) // 2\n",
    "fig, axes = plt.subplots(rows, 2, sharex=True, sharey=True, figsize=(8, 4*rows))\n",
    "for (clf, name), ax in zip(classifiers, axes.ravel()):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    score = clf.score(X_test, Y_test)\n",
    "    grid_out = clf.predict(grid_input).reshape(grid_x.shape)\n",
    "\n",
    "    ax.set_title(f'Classifier: {name}, Acc.: {score:.3f}')\n",
    "    ax.contourf(grid_x, grid_y, grid_out, alpha=0.5, cmap=plt.cm.RdBu)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=cmap, edgecolor='k')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3.3 Scikit-Learn API (optional)\n",
    "1. Consider the following new artificial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X * np.array([1, 10])\n",
    "new_Y = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Try running the algorithms as they are on this dataset and also plot the decision regions (Tip: Modularize my code to make it reusable). What changes? Do you have any idea what could cause problems here?\n",
    "2. One very commonly used technique to preprocess data is to rescale each input feature to have zero mean and unit variance before running a classifier on the data. This behaviour is already implemented by the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class. Also have a look at the [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class and use this to re-implement the traning procedure with an additinal data-normalization step. Create a new plot that compares the decision surfaces of classifiers trained on normalized data to those trained with non-normalized data.\n",
    "3. The behaviour of both SVMs is influenced by the parameter `C` and the RBF SVM also accepts a paramter `gamma`. Snce those parameters are not learned as part of the algorithm, they are also called *hyperparameter*. Play around with those and see how the decision surface changes.\n",
    "4. In part 3 you have probably seen that the value of hyperparameters can have a dramatic influence on the performance of the classifier. Tuning them by hand can be a tedious task and it is therefore preferred to automatcally try values from a specified range or even just random values. Check out the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) class and try to find a good combination of hyperparameter values for the RBF SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3.4 $k$-Nearest Neighbours\n",
    "One of the simplest machine learning algorithms (in fact so simple that you will probably be able to find convincing arguments that it is not a machine learning algorithm at all) is the $k$-nearest neighbours algorithm. Given some training examples $D = \\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}$ and a test point $x^*$, for which we would like to predct a class label, the algorithm works as follows:\n",
    "* **Training**: The training examples $D = \\{(x_i, y_i)\\}_{i=1}^{n}$ are stored.\n",
    "* **Prediction**: The $k$ training points with the least distance to $x^*$ are fetched along with their class labels, i.e.\n",
    "\\begin{equation*}\n",
    "    P_{x^*}^k := \\operatorname{arg\\ min}_{\\{y_{i_1}, \\ldots, y_{i_k}\\}} \\sum_{j=1}^{k} d(x_{i_j}, x^*),\n",
    "\\end{equation*}\n",
    "where $d$ is some distance measure. The class that appears most often in that set is then returned as the class label of $x^*$. In case of a tie, one could, for example, choose a class randomly or according to some other tie-breaker rule.\n",
    "\n",
    "Your tasks are as follows:\n",
    "1. Implement the $k$-nearest neighbours algorithm by filling in the gaps in the skeleton that has already been prepared for you. Use the Euclidean distance and when a tie occurs break it by deterministically choosing the smallest class label.\n",
    "2. Note that the `KNN` class conforms to the API of Scikit-Learn. Compare what happens when you use different values for $k$, namely $k \\in \\{1, 2, 5, 10, 15, 20\\}$. How do the decision surfaces for different values of $k$ look like when training on the two moons dataset?\n",
    "3. Can you think of a disadvantage the $k$-NN classifier might have when it is applied to real-world datasets? Insert a new markdown cell at the end of the notebook and state one such disadvantage together with two or three sentences where you explain the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "def euclidean_distance(a, b, keepdims=False):\n",
    "    raise NotImplementedError\n",
    "\n",
    "class KNN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=5, dist_function=euclidean_distance):\n",
    "        super(KNN, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.dist_function = dist_function\n",
    "        self.train_points = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # TODO:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        #TODO:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "# Generate toy data (two moons dataset)\n",
    "# Please don't modify this part for this exercise\n",
    "n = 200\n",
    "X, Y = datasets.make_moons(n, noise=0.25, random_state=1234)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=12345)\n",
    "# From now on you can modify stuff again\n",
    "\n",
    "classifiers = [(KNN(k), f'KNN ($k={k}$)') for k in [1, 2, 5, 10, 15, 20]]\n",
    "# TODO: Plot decision surfaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
